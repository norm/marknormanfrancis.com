#!/usr/bin/env python

"""
Query your tweets from a Twitter data export to find interesting tweets.
For some value of interesting that probably means a level of interaction
from other people.

Download twitter data from https://twitter.com/settings/your_twitter_data 
"""


import argparse
import os
import json
import sys

tweets = {}

def main():
    global tweets

    parser = argparse.ArgumentParser(
        description=(
            'Show matching tweets from a Twitter data export.'
        )
    )
    parser.add_argument(
        '--minimum-retweet',
        type=int,
        default=0,
        help='tweet must have more than this many retweets'
    )
    parser.add_argument(
        '--minimum-like',
        type=int,
        default=0,
        help='tweet must have more than this many likes'
    )
    parser.add_argument(
        '--thread-count',
        type=int,
        default=0,
        help='tweet must be part of a thread more than this many long'
    )
    parser.add_argument('directory')
    parser.add_argument(
        '--media',
        action='store_true',
        help='tweet must have media attachments',
    )
    args = parser.parse_args()

    with open('%s/data/tweet.js' % args.directory, 'r') as handle:
        tweets_data = handle.read()

    if tweets_data.startswith('window.YTD.tweet.part0'):
        tweets_data = tweets_data[25:]

    for tweet in json.loads(tweets_data):
        tweet_id = tweet['tweet']['id']
        tweets[tweet_id.rjust(25, '0')] = tweet['tweet']

    found = {}
    for tweet_id in sorted(tweets):
        include = True
        tweet = tweets[tweet_id]
        tweet['thread_count'] = count_thread(tweet)

        if int(tweet['retweet_count']) < args.minimum_retweet:
            include = False
        if int(tweet['favorite_count']) < args.minimum_like:
            include = False
        if tweet['thread_count'] < args.thread_count:
            include = False
        if args.media and 'media' not in tweet['entities']:
            include = False

        if include:
            found[tweet_id] = tweet

    # report only the tail of a thread, not each tweet along the way
    for tweet_id in found.copy():
        if 'in_reply_to_status_id_str' in found[tweet_id]:
            follow = found[tweet_id]['in_reply_to_status_id_str'].rjust(25, '0')
            try:
                del(found[follow])
            except KeyError:
                pass

    for tweet_id in found:
        tweet = found[tweet_id]
        print(
            '== %s %s l:%s rt:%s tc:%s\n%s' % (
                tweet['id'],
                tweet['created_at'],
                tweet['favorite_count'],
                tweet['retweet_count'],
                tweet['thread_count'],
                tweet['full_text'],
            )
        )
        if 'media' in tweet['entities']:
            for media in tweet['entities']['media']:
                print(media['media_url_https'])
        print('')

def count_thread(tweet):
    global tweets

    current = tweet
    count = 0
    while 'in_reply_to_status_id_str' in current:
        follow = current['in_reply_to_status_id_str'].rjust(25, '0')
        count += 1
        try:
            current = tweets[follow]
        except KeyError:
            current = {}
    return count

if __name__ == '__main__':
    main()
