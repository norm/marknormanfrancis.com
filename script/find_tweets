#!/usr/bin/env python

"""
Query your tweets from a Twitter data export to find interesting tweets.
For some value of interesting that probably means a level of interaction
from other people.

Download twitter data from https://twitter.com/settings/your_twitter_data 
"""


import argparse
from datetime import datetime, date
from dateutil import parser as dt_parser
import os
import json
import re
import sys

import pytz

tweets = {}

def main():
    global tweets

    parser = argparse.ArgumentParser(
        description='Show matching tweets from a Twitter data export.',
        epilog=(
            'Dates are expected to be ISO formatted, and the before/after '
            'arguments can include times (eg. 2020-01-01T13:00:00).'
        )
    )
    parser.add_argument(
        '--minimum-retweet',
        type=int,
        default=0,
        help='tweet must have more than this many retweets'
    )
    parser.add_argument(
        '--minimum-like',
        type=int,
        default=0,
        help='tweet must have more than this many likes'
    )
    parser.add_argument(
        '--thread-count',
        type=int,
        default=0,
        help='tweet must be part of a thread more than this many long'
    )
    parser.add_argument(
        '--retweet',
        action='store_true',
        help='tweet must be a retweet',
    )
    parser.add_argument(
        '--skip-retweet',
        action='store_true',
        help='tweet cannot be a retweet'
    )
    parser.add_argument(
        '--reply',
        action='store_true',
        help='tweet must be a reply',
    )
    parser.add_argument(
        '--reply-to',
        help='tweet must be a reply to REPLY_TO',
    )
    parser.add_argument(
        '-r', '--skip-reply',
        action='store_true',
        help='skip replies'
    )
    parser.add_argument(
        '--media',
        action='store_true',
        help='tweet must have media attachments',
    )
    parser.add_argument(
        '--skip-media',
        action='store_true',
        help='skip tweets with media attachments',
    )
    parser.add_argument(
        '--hashtag',
        action='append',
        default=[],
        help='tweet must include this hashtag',
    )
    parser.add_argument(
        '--skip-hashtag',
        action='append',
        default=[],
        help='skip tweets that include this hashtag',
    )
    parser.add_argument(
        '--before',
        metavar='DATE',
        type=datetime.fromisoformat,
        help='tweet must be before DATE'
    )
    parser.add_argument(
        '--after',
        metavar='DATE',
        type=datetime.fromisoformat,
        help='tweet must be on or after DATE'
    )
    parser.add_argument(
        '--date',
        metavar='DATE',
        type=date.fromisoformat,
        help='tweet must be from DATE'
    )
    parser.add_argument(
        '--text',
        action='append',
        default=[],
        help='tweet must include TEXT (regexp accepted)',
    )
    parser.add_argument(
        '--skip-text',
        action='append',
        default=[],
        help='skip tweets that match TEXT (regexp accepted)',
    )
    parser.add_argument(
        'directory',
        nargs='?',
        default=os.getenv('TWITTER_EXPORT', None),
        help=(
            'directory that contains Twitter data export '
            '(or set via env in TWITTER_EXPORT)'
        )
    )
    args = parser.parse_args()
    if not args.directory:
        parser.print_usage()
        sys.exit(1)
    if args.retweet and args.skip_retweet:
        print('--retweet and --skip-retweet cannot be specified together')
        sys.exit(1)
    if (args.reply or args.reply_to) and args.skip_retweet:
        print('--reply/--reply-to and --skip-reply cannot be specified together')
        sys.exit(1)
    if args.hashtag and args.skip_hashtag:
        for tag in args.hashtag:
            if tag in args.skip_hashtag:
                print(
                    '--hashtag and --skip-hashtag cannot be specified '
                    'with the same value'
                )
                sys.exit(1)
    if args.date and (args.before or args.after):
        print('--date and --before/--after cannot be specified together')
        sys.exit(1)
    if args.before and args.after:
        if args.before <= args.after:
            print(
                '--before dates must occur beyond --after dates '
                'if both are specified'
            )
            sys.exit(1)
    if args.before:
        args.before = pytz.timezone('UTC').localize(args.before)
    if args.after:
        args.after = pytz.timezone('UTC').localize(args.after)
    if args.text and args.skip_text:
        for match in args.text:
            if match in args.skip_text:
                print(
                    '--text and --skip-text cannot be specified '
                    'with the same value'
                )
                sys.exit(1)

    with open('%s/data/tweet.js' % args.directory, 'r') as handle:
        tweets_data = handle.read()

    if tweets_data.startswith('window.YTD.tweet.part0'):
        tweets_data = tweets_data[25:]

    for tweet in json.loads(tweets_data):
        tweet_id = tweet['tweet']['id']
        tweets[tweet_id.rjust(25, '0')] = tweet['tweet']

    found = {}
    for tweet_id in sorted(tweets):
        include = True
        tweet = tweets[tweet_id]
        tweet['thread_count'] = count_thread(tweet)
        has_tags = [
            tag['text']
            for tag in tweet['entities']['hashtags']
        ]

        if int(tweet['retweet_count']) < args.minimum_retweet:
            include = False
        if int(tweet['favorite_count']) < args.minimum_like:
            include = False
        if tweet['thread_count'] < args.thread_count:
            include = False
        if tweet['full_text'].startswith('RT @') and args.skip_retweet:
            include = False
        if not tweet['full_text'].startswith('RT @') and args.retweet:
            include = False
        if args.skip_reply and tweet['full_text'].startswith('@'):
            include = False
        if args.reply and not tweet['full_text'].startswith('@'):
            include = False
        if args.reply_to and \
            not tweet['full_text'].startswith('@%s' % args.reply_to):
                include = False
        if args.hashtag:
            for tag in args.hashtag:
                if tag not in has_tags:
                    include = False
        if args.skip_hashtag:
            for tag in args.skip_hashtag:
                if tag in has_tags:
                    include = False
        if args.before or args.after or args.date:
            created_at = dt_parser.parse(tweet['created_at'])
            if args.date:
                    if args.date != created_at.date():
                        include = False
            if args.before and created_at > args.before:
                include = False
            if args.after and created_at < args.after:
                include = False
        if args.media and 'media' not in tweet['entities']:
            include = False
        if args.skip_media and 'media' in tweet['entities']:
            include = False
        if args.text:
            for match in args.text:
                if not re.search(match, tweet['full_text']):
                    include = False
        if args.skip_text:
            for match in args.skip_text:
                if re.search(match, tweet['full_text']):
                    include = False

        if include:
            found[tweet_id] = tweet

    # report only the tail of a thread, not each tweet along the way
    for tweet_id in found.copy():
        if 'in_reply_to_status_id_str' in found[tweet_id]:
            follow = found[tweet_id]['in_reply_to_status_id_str'].rjust(25, '0')
            try:
                del(found[follow])
            except KeyError:
                pass

    for tweet_id in found:
        tweet = found[tweet_id]
        print(
            '== %s %s l:%s rt:%s tc:%s\n%s' % (
                tweet['id'],
                tweet['created_at'],
                tweet['favorite_count'],
                tweet['retweet_count'],
                tweet['thread_count'],
                tweet['full_text'],
            )
        )
        if 'media' in tweet['entities']:
            for media in tweet['entities']['media']:
                print(media['media_url_https'])
        print('')

def count_thread(tweet):
    global tweets

    current = tweet
    count = 0
    while 'in_reply_to_status_id_str' in current:
        follow = current['in_reply_to_status_id_str'].rjust(25, '0')
        count += 1
        try:
            current = tweets[follow]
        except KeyError:
            current = {}
    return count

if __name__ == '__main__':
    main()
