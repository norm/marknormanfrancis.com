#!/usr/bin/env python

"""
Add selected tweets from a list of tweet IDs.
"""

import os
import sys

import pytz
import tweepy

from django.utils.text import slugify

from lib import update_toml
from lib.bucket import Bucket

auth = tweepy.OAuthHandler(
    os.getenv('CONSUMER_KEY'),
    os.getenv('CONSUMER_SECRET')
)
auth.set_access_token(
    os.getenv('TWITTER_TOKEN'),
    os.getenv('TOKEN_SECRET')
)
twitter = tweepy.API(auth)
BUCKET = 'mnf.m17s.net'
bucket = Bucket(BUCKET)


def main():
    global twitter

    with open('data/tweet_ids.txt', 'r') as handle:
        ids = handle.readlines()

    for line in ids:
        entry = line.split(maxsplit=1)
        id = entry[0]
        tweet = twitter.get_status(id, tweet_mode='extended')
        created = tweet.created_at
        if not created.tzinfo:
            created = pytz.timezone('UTC').localize(created)

        # FIXME hashtags
        # FIXME quote tweets
        # FIXME retweets
        # FIXME threads
        # FIXME attached images/video
        # FIXME add original data as attachment

        markdown_text = tweet_to_markdown(tweet)

        try:
            title = entry[1].rstrip()
        except IndexError:
            title = 'Tweet at %s' % created.strftime('%-I:%M%p').lower()

        post = {
            'tweet_id': tweet.id_str,
            'tweet_markdown': markdown_text,
            'type': 'tweet',
            'title': title,
            'published': created,
            'retweeted': tweet.retweet_count,
            'favourited': tweet.favorite_count,
            'original_url': 'https://twitter.com/%s/status/%s' % (
                tweet.author.screen_name,
                tweet.id_str,
            ),
            'images': [],
        }

        date = created.strftime('%Y/%m/%d')

        if 'media' in tweet.entities:
            for media in tweet.entities['media']:
                destination = '%s/%s' % (
                    date,
                    os.path.basename(media['media_url_https']),
                )
                uploaded = bucket.upload_file(
                    media['media_url_https'],
                    destination,
                    check_digest = False,
                )
                if uploaded:
                    print('++', destination)
            post['images'].append('http://%s/%s' % (BUCKET, destination))

        toml_file = 'source/%s/tweet-%s.toml' % (date, tweet.id_str)
        update_toml(toml_file, post)

def tweet_to_markdown(tweet):
    sections = []
    markdown = ''

    if 'urls' in tweet.entities:
        for url in tweet.entities['urls']:
            sections.append(url)
    if 'user_mentions' in tweet.entities:
        for mention in tweet.entities['user_mentions']:
            sections.append(mention)
    if 'hashtags' in tweet.entities:
        for tag in tweet.entities['hashtags']:
            sections.append(tag)

    text_from = 0
    for section in sorted(sections, key=lambda s: s['indices'][0]):
        start = section['indices'][0]
        markdown += tweet.full_text[text_from:start]
        if 'screen_name' in section:
            markdown += '[@%s](%s)' % (
                section['screen_name'],
                'https://twitter.com/%s' % section['screen_name'],
            )
        if 'display_url' in section:
            markdown += '[`%s`](%s)' % (
                section['display_url'],
                section['expanded_url']
            )
        if 'text' in section:
            markdown += '[#%s](/tags/%s/)' % (
                section['text'],
                slugify(section['text'])
            )
        text_from = section['indices'][1]
    if text_from < tweet.display_text_range[1]:
        markdown += tweet.full_text[text_from:tweet.display_text_range[1]]
    return markdown


if __name__ == '__main__':
    main()
