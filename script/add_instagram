#!/usr/bin/env python

"""
Add all photos from an Instagram backup.

Get the backup by signing into Instagram in a browser, then going to
https://www.instagram.com/download/request/

Eventually Facebook will send you the zip of your Instagram data.

Run this script with the directory as the argument:

    % python script/add_instagram ~/Downloads/instagram_export...

The backup data does not include a reference to the original URL. Nor can you
tie the comments to the image they are commenting on. I mean, why be helpful,
right? But I can live with that. I won't lose sleep at failing to preserve
those links.
"""

from datetime import datetime
from hashlib import md5
import json
import os
import sys
import pytz

import boto3
from django.utils.text import slugify

from lib import update_toml
from lib.bucket import Bucket

# two duplicates and an error
ignored = [
    'photos/201410/ff9f2c686b5b5109b7c6fa9db647c777.jpg',
    'photos/201412/8cf4d9a24e9855201eec657d44c553be.jpg',
    'photos/201109/a6529709606f9a2ddb232ed53f27d7bb.jpg',
]

BUCKET='mnf.m17s.net'
instagram_export = sys.argv[1]


def main():
    bucket = Bucket(BUCKET)
    media = read_media()
    seen = []

    for photo in media['photos']:
        if photo['path'] in ignored:
            continue

        taken = datetime.fromisoformat(photo['taken_at'])
        if not taken.tzinfo:
            # why have a timezone, everyone's in San Francisco right?
            sf_taken = pytz.timezone('America/Los_Angeles').localize(taken)
            taken = sf_taken.astimezone(pytz.utc)
        subdir = taken.strftime('%Y/%m/%d')
        caption = strip_trailing_hashtags(photo['caption'])
        slug = slugify(caption)
        if not slug:
            slug = 'image'

        path = '%s/%s' % (subdir, slug)
        if path in seen:
            path = '%s/%s-%s' % (subdir, taken.strftime('%H%M%S'), slug)
            if path in seen:
                raise DuplicateError

        image_path = '%s.jpg' % path
        uploaded = bucket.upload_file(
            '%s/%s' % (instagram_export, photo['path']),
            image_path,
        )
        if uploaded:
            print('++ s3://%s/%s' % (BUCKET, image_path))

        metadata = {
            'published': taken,
            'title': caption,
            'image': 'http://%s/%s' % (BUCKET, image_path),
            'type': 'instagram',
        }
        if 'location' in photo:
            metadata['location'] = photo['location']
        if caption != photo['caption']:
            metadata['original_caption'] = photo['caption']

        tags = get_hashtags(photo['caption'])
        if tags:
            metadata['tag'] = sorted(tags)

        toml_file = 'source/%s.toml' % path
        update_toml(toml_file, metadata)

        seen.append(path)

def get_hashtags(text):
    """
    Return a set of hashtags found in the text,
    ignoring shorthand ordinal numbers (eg we're #1!).
    """
    tags = set(
        slugify(word[1:].lower())
        for word in text.split()
        if word.startswith('#')
    )
    for tag in tags.copy():
        try:
            int(tag)
            tags.remove(tag)
        except ValueError:
            pass
    return tags

def strip_trailing_hashtags(text):
    """
    Remove hashtags from the end of a string, but not from the middle.
    """
    if not text:
        return ''
    words = [
        word 
        for word in text.split(' ')
        if word
    ]
    if words[-1].startswith('#'):
        while words and words[-1].startswith('#'):
            del words[-1]
    return ' '.join(words)


def read_media():
    instagram_export = sys.argv[1]
    media_json = os.path.join(instagram_export, 'media.json')

    with open(media_json, 'r') as media_handle:
        return json.load(media_handle)

if __name__ == '__main__':
    main()
